{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build a simple Chatbot with stored memory using LangChain\n",
    "* Simple Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to store memory in a json file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c88f7",
   "metadata": {},
   "source": [
    "A chatbot app is a software application designed to simulate conversation with human users. It uses artificial intelligence (AI) to understand what someone is saying and to respond with appropriate answers. These apps can be used for various purposes like customer support, providing information, or entertainment. Essentially, it's like texting with a program that can answer questions and help with tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584e1f0-5e9e-4e45-850c-c606234b6ee2",
   "metadata": {},
   "source": [
    "## Trick to avoid the nasty deprecation warnings from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4224a-d719-46fd-b261-dd913b17ec86",
   "metadata": {},
   "source": [
    "In this exercise we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eddbcf93-0b58-4506-af83-2fa2203c711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8626f160-fcd3-41ca-a5ab-3e98f11595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6d60-5cbd-43e4-9a69-ed71d82a2a9b",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bdc4c-484d-4ec0-89b6-5f1e979610ce",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is blue.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a great choice! Blue is often associated with calmness, serenity, and tranquility. What do you like most about the color blue?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 13, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-17438b42-d52f-4b38-b95a-011d0f71a06b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 32, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09f0b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I cannot determine your favorite color as I do not have information about your personal preferences.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 13, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5e2cfafd-8407-4add-b076-88fb07ecec4d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 22, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8180e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70dbdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6062df1-33ce-436e-b5b2-cea78ae7b860",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "735752cc-ecb5-4942-9ed0-b3213f5768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "542bbf66-bc77-4488-8487-b55cdb8bc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0027a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e8431b-5290-4f7f-9566-a90deb060bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=ConversationBufferMemory(chat_memory=<langchain_community.chat_message_histories.file.FileChatMessageHistory object at 0x10c5a3310>, return_messages=True, memory_key='messages'), verbose=False, prompt=ChatPromptTemplate(input_variables=['content', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10ac16840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[MessagesPlaceholder(variable_name='messages'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, template='{content}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10c70ffd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ca16f90>, root_client=<openai.OpenAI object at 0x10c41ce90>, root_async_client=<openai.AsyncOpenAI object at 0x10c70ec90>, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm = chatbot,\n",
    "    prompt = prompt,\n",
    "    memory = memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72392539-0f20-456b-b32d-d367b48245f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'hi ',\n",
       " 'messages': [],\n",
       " 'text': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hi \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e40af4-1539-497d-afbf-ed38fed90838",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"hi \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b79cc08-49dd-4746-ab68-9d8ec992abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'my name is prince katiyar  ',\n",
       " 'messages': [HumanMessage(content='hi ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"It's nice to meet you, Prince Katiyar! How can I help you today?\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"my name is prince katiyar  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e4e158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'My favorite color is blue',\n",
       " 'messages': [HumanMessage(content='hi ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my name is prince katiyar  ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"It's nice to meet you, Prince Katiyar! How can I help you today?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"Blue is a great color choice! It's often associated with calmness and stability. Do you have a specific reason why blue is your favorite color?\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"My favorite color is blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf7aefc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my name',\n",
       " 'messages': [HumanMessage(content='hi ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my name is prince katiyar  ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"It's nice to meet you, Prince Katiyar! How can I help you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My favorite color is blue', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Blue is a great color choice! It's often associated with calmness and stability. Do you have a specific reason why blue is your favorite color?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your name is Prince Katiyar.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ddf37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my faviorite color',\n",
       " 'messages': [HumanMessage(content='hi ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my name is prince katiyar  ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"It's nice to meet you, Prince Katiyar! How can I help you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My favorite color is blue', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Blue is a great color choice! It's often associated with calmness and stability. Do you have a specific reason why blue is your favorite color?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Prince Katiyar.', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your favorite color is blue.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my faviorite color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e69c4f-b5ed-4c68-9a2a-67a19867f8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44245124-ef39-4269-a099-21c9c31c08bb",
   "metadata": {},
   "source": [
    "* Check the file messages.json in the root directory.\n",
    "* This is just a simple example, in the real world you probably will not save your memory in a json file. \n",
    "* And remember: the context window is limited and it affects to the cost of using chatGPT API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9faf6-2772-4ef5-8241-d1e00c761ca4",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-simple-chatbot.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-simple-chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ba3a6-ff9c-49c5-b5a0-23f2ff7b367c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5064c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c3071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
