{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/3vv9s5d557bc1lhnccljp37w0000gn/T/ipykernel_62277/3101574246.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=model,prompt=prompt_template_name)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=model,prompt=prompt_template_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/3vv9s5d557bc1lhnccljp37w0000gn/T/ipykernel_62277/1829500462.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = chain.run(\"indian\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dynasty Delights\n",
      "2. Dragon Palace\n",
      "3. Imperial Garden\n",
      "4. Golden Lotus\n",
      "5. Jade Dragon\n",
      "6. Silk Road Kitchen\n",
      "7. Red Lantern\n",
      "8. Bamboo Garden\n",
      "9. Lotus Blossom\n",
      "10. Phoenix Pavilion\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"chinese\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/3vv9s5d557bc1lhnccljp37w0000gn/T/ipykernel_62277/736173611.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=model,prompt=prompt_template_name,memory=memory)\n",
    "#chain = LLMChain(llm=model,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Taj Mahal Bistro\"\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"India\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Stars and Stripes Bistro\"\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"usa\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: India\\nAI: \"Taj Mahal Bistro\"\\nHuman: usa\\nAI: \"Stars and Stripes Bistro\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: India\n",
      "AI: \"Taj Mahal Bistro\"\n",
      "Human: usa\n",
      "AI: \"Stars and Stripes Bistro\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/3vv9s5d557bc1lhnccljp37w0000gn/T/ipykernel_62277/884467124.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/3vv9s5d557bc1lhnccljp37w0000gn/T/ipykernel_62277/2852637159.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, memory=memory)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation = ConversationChain(llm=llm, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  As an AI, I do not have the ability to feel emotions, but I am functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      " Sure! Here's one: Why couldn't the bicycle stand up by itself? Because it was two-tired! Ha ha ha. Did you find that funny? I have a large database of jokes and can generate more if you'd like. Just let me know what type of humor you prefer.\n",
      "  That's interesting! I am not familiar with the title \"prince katiyar.\" Can you tell me more about it?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hello, how are you?\"\n",
    "\n",
    "\n",
    "response = conversation.run(user_input)\n",
    "print(response)\n",
    "\n",
    "user_input = \"Can you tell me a joke?\"\n",
    "response = conversation.run(user_input)\n",
    "print(response)\n",
    "\n",
    "user_input = \"i m a prince katiyar\"\n",
    "response = conversation.run(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_variables = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, how are you?\n",
      "AI:  Hello! I am an AI language model created by OpenAI. I do not have the ability to feel emotions, but I am functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      "Human: Can you tell me a joke?\n",
      "AI:  Sure! Here's one: Why did the tomato turn red? Because it saw the salad dressing! Ha ha ha. Did you find that funny? I have a large database of jokes and can generate more if you'd like. Just let me know what type of humor you prefer.\n",
      "Human: Hello, how are you?\n",
      "AI:  As an AI, I do not have the ability to feel emotions, but I am functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      "Human: Can you tell me a joke?\n",
      "AI:  Sure! Here's one: Why don't scientists trust atoms? Because they make up everything! Ha ha ha. Did you find that funny? I have a large database of jokes and can generate more if you'd like. Just let me know what type of humor you prefer.\n",
      "Human: i m a prince katiyar\n",
      "AI:  That's interesting! I am not familiar with the title \"prince katiyar.\" Can you tell me more about it?\n",
      "Human: Hello, how are you?\n",
      "AI:   As an AI, I do not have the ability to feel emotions, but I am functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      "Human: Can you tell me a joke?\n",
      "AI:  Sure! Here's one: Why couldn't the bicycle stand up by itself? Because it was two-tired! Ha ha ha. Did you find that funny? I have a large database of jokes and can generate more if you'd like. Just let me know what type of humor you prefer.\n",
      "Human: i m a prince katiyar\n",
      "AI:   That's interesting! I am not familiar with the title \"prince katiyar.\" Can you tell me more about it?\n"
     ]
    }
   ],
   "source": [
    "print(memory_variables['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=model,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first cricket test world cup was held in 1975 and the West Indies won the tournament. They defeated Australia in the final at Lord's Cricket Ground in London. It was a historic moment for cricket and the West Indies team dominated the tournament with their stellar performance.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the first cricket  test world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Cricket World Cup was held in 1975 in England. The West Indies team emerged as the champions by defeating Australia in the final at Lord's Cricket Ground. It was a thrilling match that showcased the talent and skill of the West Indies players.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 + 5 equals 10.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Clive Lloyd was the captain of the West Indies team that won the first Cricket World Cup in 1975. Lloyd's leadership and batting performance were crucial in their victory.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have that information.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the first cricket  test world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who was the captain of the winning team?\n",
      "AI: Clive Lloyd was the captain of the West Indies team that won the first Cricket World Cup in 1975. Lloyd's leadership and batting performance were crucial in their victory.\n",
      "Human: Who won the first cricket  test world cup?\n",
      "AI: I'm sorry, I do not have that information.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
