{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Prompting with Examples \n",
    "Zero-Shot Prompting:\n",
    "Ask a task without examples.\n",
    "Example: \"Translate this to French: Hello.\"\n",
    "\n",
    "One-Shot Prompting:\n",
    "Provide one example before the task.\n",
    "Example:\n",
    "\"Translate: 'Hello -> Bonjour'. Now, translate: 'Goodbye'.\"\n",
    "\n",
    "Few-Shot Prompting:\n",
    "Provide a few examples to guide the model.\n",
    "Example:\n",
    "\"Translate: 'Hello -> Bonjour', 'Cat -> Chat'. Now, translate: 'Dog'.\"\n",
    "\n",
    "Chain-of-Thought Prompting:\n",
    "Encourage step-by-step reasoning.\n",
    "Example:\n",
    "\"Calculate: If 5 apples cost $10, what is the cost of 2 apples? Step-by-step, first find the cost of 1 apple...\"\n",
    "\n",
    "Role-Based Prompting:\n",
    "Assign a role to influence tone or expertise.\n",
    "Example:\n",
    "\"You are a teacher. Explain Python functions to beginners.\"\n",
    "\n",
    "Instruction-Based Prompting:\n",
    "Provide detailed instructions for specific output.\n",
    "Example:\n",
    "\"Summarize the text in 3 bullet points.\"\n",
    "\n",
    "Interactive Prompting:\n",
    "Use iterative inputs for clarification or refinement.\n",
    "Example:\n",
    "\"Rewrite this text to make it formal. If unclear, ask questions.\"\n",
    "\n",
    "Prompt Chaining:\n",
    "Break tasks into smaller parts.\n",
    "Example:\n",
    "\"First, generate a title. Then create an outline. Finally, write the content.\"\n",
    "\n",
    "Contextual Prompting:\n",
    "Provide relevant context for better responses.\n",
    "Example:\n",
    "\"Based on the given paragraph, summarize it in one sentence.\"\n",
    "\n",
    "Multimodal Prompting:\n",
    "Use text along with other inputs like images.\n",
    "Example:\n",
    "\"Describe the attached image in one sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Prompt Engineering Tips (Short Version)\n",
    "Be Clear:\n",
    "Use specific and precise instructions. Example: \"Summarize in 2 sentences.\"\n",
    "\n",
    "Define Output Format:\n",
    "Request structured responses like bullet points, JSON, or HTML.\n",
    "\n",
    "Ask for a Self-Check:\n",
    "Add checks like: \"If unsure, respond with 'No information.'\"\n",
    "\n",
    "Use Delimiters or Tags:\n",
    "Separate instructions and context clearly to avoid confusion.\n",
    "\n",
    "Role Prompting:\n",
    "Assign a role to the model to adjust style and tone, e.g., \"Act as a mathematician.\"\n",
    "\n",
    "Limit Context:\n",
    "Use only the most relevant parts of a document to improve response accuracy.\n",
    "\n",
    "Show Examples:\n",
    "Provide examples to guide the model toward desired responses.\n",
    "\n",
    "Ask for Explanation:\n",
    "Request reasoning to improve accuracy, especially for logical tasks.\n",
    "\n",
    "Provide Step-by-Step Instructions:\n",
    "Include detailed steps or examples for better problem-solving.\n",
    "\n",
    "Split Tasks:\n",
    "Break complex tasks into smaller subtasks (prompt chaining) for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "How can I effectively prepare for my board exams?\n",
    "Example: 'Create a schedule for one week in a tabular format'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chatModel.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a sample one-week study schedule in a tabular format:\n",
      "\n",
      "| Time         | Monday                | Tuesday               | Wednesday             | Thursday              | Friday                | Saturday              | Sunday                |\n",
      "|--------------|-----------------------|-----------------------|-----------------------|-----------------------|-----------------------|-----------------------|-----------------------|\n",
      "| 8:00-9:00 AM | Review Math           | Review Science        | Review English        | Review History        | Review Geography      | Practice Previous Exams| Take a Break          |\n",
      "| 9:00-10:00 AM| Practice Math Problems| Practice Science Problems| Practice English Grammar| Practice History dates| Practice Geography concepts| Mock Test            | Rest & Relax          |\n",
      "| 10:00-11:00 AM| Break & Snack        | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         |\n",
      "| 11:00-12:00 PM| Solve Math Questions | Solve Science Questions | Solve English Comprehension| Solve History Questions| Solve Geography Questions| Check Answers        | Review Weak Areas     |\n",
      "| 12:00-1:00 PM | Lunch & Rest         | Lunch & Rest          | Lunch & Rest          | Lunch & Rest          | Lunch & Rest          | Lunch & Rest          | Lunch & Rest          |\n",
      "| 1:00-2:00 PM  | Practice Math Formulas| Practice Science Formulas| Practice English Vocabulary| Practice History Events| Practice Geography Maps| Mock Test Feedback    | Relax & Leisure Time  |\n",
      "| 2:00-3:00 PM  | Review Notes         | Review Notes          | Review Notes          | Review Notes          | Review Notes          | Review Notes          | Review Notes          |\n",
      "| 3:00-4:00 PM  | Break & Snack        | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         | Break & Snack         |\n",
      "| 4:00-5:00 PM  | Practice Previous Year Papers| Practice Previous Year Papers| Practice Previous Year Papers| Practice Previous Year Papers| Practice Previous Year Papers| Practice Previous Year Papers| Practice Previous Year Papers|\n",
      "| 5:00-6:00 PM  | Take a Break         | Take a Break          | Take a Break          | Take a Break          | Take a Break          | Take a Break          | Take a Break          |\n",
      "| 6:00-7:00 PM  | Review Concepts      | Review Concepts       | Review Concepts       | Review Concepts       | Review Concepts       | Review Concepts       | Review Concepts       |\n",
      "| 7:00-8:00 PM  | Dinner & Relax       | Dinner & Relax        | Dinner & Relax        | Dinner & Relax        | Dinner & Relax        | Dinner & Relax        | Dinner & Relax        |\n",
      "| 8:00-9:00 PM  | Solve Sample Papers  | Solve Sample Papers   | Solve Sample Papers   | Solve Sample Papers   | Solve Sample Papers   | Solve Sample Papers   | Solve Sample Papers   |\n",
      "| 9:00-10:00 PM | Revise Important Topics| Revise Important Topics| Revise Important Topics| Revise Important Topics| Revise Important Topics| Revise Important Topics| Revise Important Topics|\n",
      "| 10:00 PM      | Bedtime              | Bedtime               | Bedtime               | Bedtime               | Bedtime               | Bedtime               | Bedtime               |\n",
      "\n",
      "Feel free to adjust the schedule based on your own study habits and preferences. Good luck with your board exams!\n"
     ]
    }
   ],
   "source": [
    "study_schedule = response.content\n",
    "print(study_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "How can I effectively prepare for my board exams?\n",
    "Example 1: 'Divide the syllabus into smaller parts and focus on one section at a time.'\n",
    "Example 2: 'Review past papers to get familiar with the exam pattern.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: 'Create a study schedule and stick to it, making sure to allocate enough time for each subject.'\n",
      "Example 4: 'Seek help from teachers, classmates, or tutors if you have any doubts or difficulties understanding certain topics.'\n",
      "Example 5: 'Practice answering sample questions to improve your time management and problem-solving skills.'\n",
      "Example 6: 'Get enough rest and eat well to ensure your mind is sharp and focused during study sessions and on exam day.'\n",
      "Example 7: 'Stay organized by keeping track of important dates, deadlines, and study materials to avoid last-minute cramming.'\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(prompt)\n",
    "\n",
    "study_schedule = response.content\n",
    "print(study_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "What steps should I take to prepare borad exam you have to give fore maths , physics , chemisty in 2 days adn also give in computer plan give in tabular format\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Subject        | Steps to prepare for board exam in 2 days |\n",
      "|----------------|-------------------------------------------|\n",
      "| Maths          | 1. Review all key concepts and formulas    |\n",
      "|                | 2. Practice solving sample questions       |\n",
      "|                | 3. Create summary notes for quick revision |\n",
      "| Physics        | 1. Focus on understanding key concepts     |\n",
      "|                | 2. Solve numerical problems to practice    |\n",
      "|                | 3. Review important diagrams and graphs    |\n",
      "| Chemistry      | 1. Revise chemical reactions and equations |\n",
      "|                | 2. Practice balancing equations            |\n",
      "|                | 3. Study important concepts and definitions |\n",
      "| Computer       | 1. Review programming languages and syntax |\n",
      "|                | 2. Practice coding exercises and programs   |\n",
      "|                | 3. Familiarize yourself with key terms and concepts |\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(prompt)\n",
    "\n",
    "study_schedule = response.content\n",
    "print(study_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Translate the following English text to French: {text}\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "formatted_prompt = prompt.format(text=\"Hello, I m a prince katiyar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bonjour, je suis un prince katiyar ?\n"
     ]
    }
   ],
   "source": [
    "response = llmModel.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = chat_template.format_messages(\n",
    "    profession=\"director do a moview\",\n",
    "    topic=\"funny movie \",\n",
    "    user_input=\"give some name of funny bollywood movie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are some funny Bollywood movie suggestions:\n",
      "\n",
      "1. \"Andaz Apna Apna\"\n",
      "2. \"Hera Pheri\"\n",
      "3. \"3 Idiots\"\n",
      "4. \"Welcome\"\n",
      "5. \"Dhol\"\n",
      "6. \"Golmaal: Fun Unlimited\"\n",
      "7. \"Chup Chup Ke\"\n",
      "8. \"Hungama\"\n",
      "9. \"Masti\"\n",
      "10. \"Dhamaal\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chatModel.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an English-Spanish translator.\n",
      "Human: hi!\n",
      "AI: ¡hola!\n",
      "Human: bye!\n",
      "AI: ¡adiós!\n",
      "Human: Translate 'I am learning programming\n"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "input_text = \"Translate 'I am learning programming\"\n",
    "\n",
    "formatted_prompt = final_prompt.format(input=input_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Estoy aprendiendo programación.\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(formatted_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"output\": \"Paris\"},\n",
    "    {\"input\": \"3*3\", \"output\": \"9\"},\n",
    "    {\"input\": \"Who wrote 'To Kill a Mockingbird'?\", \"output\": \"Harper Lee\"},\n",
    "    {\"input\": \"What is 10-4?\", \"output\": \"6\"},\n",
    "    {\"input\": \"5/5\", \"output\": \"1\"},\n",
    "    {\"input\": \"What is the largest planet in the solar system?\", \"output\": \"Jupiter\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('human', '{input}'), ('ai', '{output}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    \n",
    "    example_prompt=example_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful AI Assistant\n",
      "Human: 2+2\n",
      "AI: 4\n",
      "Human: 2+3\n",
      "AI: 5\n",
      "Human: What is the capital of France?\n",
      "AI: Paris\n",
      "Human: 3*3\n",
      "AI: 9\n",
      "Human: Who wrote 'To Kill a Mockingbird'?\n",
      "AI: Harper Lee\n",
      "Human: What is 10-4?\n",
      "AI: 6\n",
      "Human: 5/5\n",
      "AI: 1\n",
      "Human: What is the largest planet in the solar system?\n",
      "AI: Jupiter\n",
      "Human: What is generative ai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are a helpful AI Assistant'),\n",
    "        few_shot_prompt,\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "formatted_prompt1 = final_prompt.format(input=\"What is generative ai\")\n",
    "print(formatted_prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Generative AI refers to artificial intelligence systems that can create new content, such as images, text, or music, based on patterns and data it has been trained on. It is often used in creative applications and can produce unique and original content.\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(formatted_prompt1)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt with chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
