{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
      "metadata": {
        "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37"
      },
      "source": [
        "# QA over SQL data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
      "metadata": {
        "id": "96a73fbf-e241-499d-a235-32a87b46ee7c"
      },
      "source": [
        "## Intro\n",
        "* We will create a Q&A app over tabular data in databases.\n",
        "* These app will allow us to **ask a question about the data in a database in natural language and get back an answer also in natural language**.\n",
        "* Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. **In production, make sure that your database connection permissions** are always scoped as narrowly as possible for your chain's needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a508d2ac-5e64-48a6-895e-2e0ab5162d1c",
      "metadata": {
        "id": "a508d2ac-5e64-48a6-895e-2e0ab5162d1c"
      },
      "outputs": [],
      "source": [
        "#!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
      "metadata": {
        "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
      "metadata": {
        "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80"
      },
      "source": [
        "## Install LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b411cb8c-4baf-43cf-bf79-e56646c90519",
      "metadata": {
        "id": "b411cb8c-4baf-43cf-bf79-e56646c90519"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
      "metadata": {
        "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
      "metadata": {
        "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941"
      },
      "source": [
        "## Connect with an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b4581b-0b47-4a00-8c72-5d4846cfea15",
      "metadata": {
        "id": "57b4581b-0b47-4a00-8c72-5d4846cfea15"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
        "outputId": "6340298c-6eec-4b9f-f24c-bbb49c080b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, huggingface_hub, pydantic-settings, dataclasses-json, langchain-core, langchain-huggingface, langchain, langchain-community\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.27.0\n",
            "    Uninstalling huggingface-hub-0.27.0:\n",
            "      Successfully uninstalled huggingface-hub-0.27.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 huggingface_hub-0.27.1 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.29 langchain-huggingface-0.1.2 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install langchain-openai\n",
        "!pip install -U langchain-community langchain langchain-huggingface huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
      "metadata": {
        "id": "a1998155-91de-4cbc-bc88-8d77beefb51b"
      },
      "source": [
        "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
      "metadata": {
        "id": "6ae8595e-5c07-4b02-8a79-db55fd357527"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACEHUB_API_TOKEN= userdata.get('HUGGING_FACE_API_KEY')\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token = HUGGINGFACEHUB_API_TOKEN)\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "chat = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    max_length=128,\n",
        "    temperature=0.7,\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
        ")\n",
        "\n",
        "# llm_chain = prompt | llm\n",
        "# print(llm_chain.invoke({\"question\": question}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLDyTwIql90n",
        "outputId": "8e18e8da-ca4d-4a7e-a2df-69d006300b71"
      },
      "id": "tLDyTwIql90n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d373482d-492a-40df-b0ac-131ed70c5259",
      "metadata": {
        "id": "d373482d-492a-40df-b0ac-131ed70c5259"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc942a2e-b9d3-4f5f-a612-f212cacc8bdd",
      "metadata": {
        "id": "bc942a2e-b9d3-4f5f-a612-f212cacc8bdd"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a99a77-abc6-412a-b9dc-651e00fe5867",
      "metadata": {
        "id": "85a99a77-abc6-412a-b9dc-651e00fe5867"
      },
      "source": [
        "## Connect with the database\n",
        "* In this example we will use a SQLite connection with the `street_tree_db` database we have in the `data` folder.\n",
        "* **Remember to download the data folder from the Github repository**.\n",
        "* The `data` folder must be in the root directory of this app.\n",
        "* We can interface with the database using the SQLAlchemy-driven `SQLDatabase` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ae1ca291-4c3f-47a6-8854-42d2ac953c15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae1ca291-4c3f-47a6-8854-42d2ac953c15",
        "outputId": "5182f092-9994-4d9a-c4f6-cb2f73ec3960"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.utilities.sql_database.SQLDatabase at 0x7f3b7f7cd240>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "sqlite_db_path = \"/content/street_tree_db.sqlite\"\n",
        "\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
        "db"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39a7a0a-059c-496f-91ee-1303aa1bb6ae",
      "metadata": {
        "id": "c39a7a0a-059c-496f-91ee-1303aa1bb6ae"
      },
      "source": [
        "We can create a simple chain that takes a question and does the following:\n",
        "* Convert the question into a SQL query;\n",
        "* Execute the query;\n",
        "* Use the result to answer the original question.\n",
        "\n",
        "The first step in a SQL chain is to take the user input and convert it to a SQL query. LangChain comes with a **built-in chain** for this, `create_sql_query_chain`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea9f155-cacc-41ad-bce8-1d9ceb318329",
      "metadata": {
        "id": "5ea9f155-cacc-41ad-bce8-1d9ceb318329"
      },
      "source": [
        "#### Step 1: Translating a question in natural language into an SQL query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bd9b7787-2076-4d6a-94ad-8c815fb1ff61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bd9b7787-2076-4d6a-94ad-8c815fb1ff61",
        "outputId": "28b35c6e-a8d4-40f8-cd0e-ad39d8da2ed6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT COUNT(DISTINCT qSpecies) FROM street_trees;'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain.chains import create_sql_query_chain\n",
        "\n",
        "chain = create_sql_query_chain(chat, db)\n",
        "\n",
        "response = chain.invoke({\"question\": \"How many species of trees are in San Francisco?\"})\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c5f7fa-0147-423f-8793-22fdbdacdd29",
      "metadata": {
        "id": "c0c5f7fa-0147-423f-8793-22fdbdacdd29"
      },
      "source": [
        "* We can execute the query to make sure it's valid:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3b598141-a7c3-4209-b0cf-626b28d677b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3b598141-a7c3-4209-b0cf-626b28d677b4",
        "outputId": "39274147-fd1d-4642-a421-6eef55476687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[(148,)]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "db.run(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71188e6d-8b78-4162-804a-918d54449b17",
      "metadata": {
        "id": "71188e6d-8b78-4162-804a-918d54449b17"
      },
      "source": [
        "* We can also inspect the chain directly for its prompts. Pay attention to the second paragraph, where it says: **\"Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\"** This is a limitation and if it is not handled well can cause errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "01fe095e-a138-4d5e-a02a-14c6d38d1786",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01fe095e-a138-4d5e-a02a-14c6d38d1786",
        "outputId": "a2016041-1236-45d0-9f05-ebb40dfd2a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
            "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
            "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
            "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use the following tables:\n",
            "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "chain.get_prompts()[0].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64WiipJRmnZJ"
      },
      "id": "64WiipJRmnZJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a2eab168-ba8d-410f-a158-631d87edb2d9",
      "metadata": {
        "id": "a2eab168-ba8d-410f-a158-631d87edb2d9"
      },
      "source": [
        "#### Step 2: Executing the SQL query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ef39e5-1b37-4673-aa4c-951fbb3e6e3f",
      "metadata": {
        "id": "71ef39e5-1b37-4673-aa4c-951fbb3e6e3f"
      },
      "source": [
        "* Now that we've generated a SQL query, we'll want to execute it.\n",
        "* When you are in production, consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution.\n",
        "* We can **use the QuerySQLDatabaseTool to easily add query execution to our chain**:\n",
        "    * The user asks a question.\n",
        "    * The write_query chain has que question as input and the SQL query as output.\n",
        "    * The execute_query chain has the SQL query as input and the SQL query execution as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e849055-8d6b-49ed-b8b3-aeb95e04b208",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e849055-8d6b-49ed-b8b3-aeb95e04b208",
        "outputId": "6dc3589e-0457-4a8d-99ba-6dd9be3cab29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "\n",
        "write_query = create_sql_query_chain(chat, db)\n",
        "\n",
        "execute_query = QuerySQLDataBaseTool(db=db)\n",
        "\n",
        "chain = write_query | execute_query\n",
        "\n",
        "output= chain.invoke({\"question\": \"List the species of trees that are present in San Francisco\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvsO52zhm8C6"
      },
      "id": "QvsO52zhm8C6",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5998cea6-43ff-4376-9a83-618995ee36a6",
      "metadata": {
        "id": "5998cea6-43ff-4376-9a83-618995ee36a6"
      },
      "source": [
        "#### Step 3: Translate the SQL response into a natural language response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f52988b3-93fd-4190-b6a5-0755fe28ecf9",
      "metadata": {
        "id": "f52988b3-93fd-4190-b6a5-0755fe28ecf9"
      },
      "source": [
        "* Now that we've got a way to generate and execute queries, we need to **combine the original question and SQL query result with the chat model to generate a final answer in natural language**.\n",
        "* We can do this by passing question and result to the LLM like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d24dee97-465f-4979-9afe-79e0b7eb6f3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d24dee97-465f-4979-9afe-79e0b7eb6f3f",
        "outputId": "7eee6e79-749d-45c9-8947-7631b96680d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Based on the information provided in the SQL result, the following tree species are present in San Francisco: \n",
            "\n",
            "1. Quercus agrifolia (Coast Live Oak)\n",
            "2. Pinus radiata (Monterey Pine)\n",
            "3. Aesculus californica (California Buckeye)\n",
            "4. Platanus racemosa (California Sycamore)\n",
            "5. Liquidambar formosana (Formosan Sweetgum)\n",
            "6. Lithocarpus densiflorus (Tanoak)\n",
            "7. Quercus lobata (Coast Redwood)\n",
            "8. Tsuga heterophylla (Western Hemlock)\n",
            "\n",
            "These tree species were identified in the SQL result due to the presence of 'San Francisco' in the 'Location' column of the 'street_trees' table.\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "sqlite_db_path = \"/content/street_tree_db.sqlite\"\n",
        "\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "answer_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"Given the following user question,\n",
        "    corresponding SQL query, and SQL result,\n",
        "    answer the user question.\n",
        "\n",
        "Question: {question}\n",
        "SQL Query: {query}\n",
        "SQL Result: {result}\n",
        "Answer: \"\"\"\n",
        ")\n",
        "\n",
        "write_query = create_sql_query_chain(chat, db)\n",
        "\n",
        "execute_query = QuerySQLDataBaseTool(db=db)\n",
        "\n",
        "#chain = write_query | execute_query\n",
        "\n",
        "#chain.invoke({\"question\": \"List the species of trees that are present in San Francisco\"})\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(query=write_query).assign(\n",
        "        result=itemgetter(\"query\") | execute_query\n",
        "    )\n",
        "    | answer_prompt\n",
        "    | chat\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "resp= chain.invoke({\"question\": \"List the species of trees that are present in San Francisco\"})\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fc31c07-a003-403d-bea6-c8965f9e8b38",
      "metadata": {
        "id": "7fc31c07-a003-403d-bea6-c8965f9e8b38"
      },
      "source": [
        "#### Let's review what is happening in the above chain.\n",
        "* The user asks a question (identified by the variable name \"question\").\n",
        "* We use RunnablePassthrough to get that \"question\" variable, and we use .assign() twice to get the other two variables required by the prompt template: \"query\" and \"result\".\n",
        "* With the first .assign(), the write_query chain has que question as input and the SQL query (identified by the variable name \"query\") as output.\n",
        "* With the second .assign(), the execute_query chain has the SQL query as input and the SQL query execution (identified by the variable name \"result\") as output.\n",
        "* The prompt template has the question (identified by the variable name \"question\"), the SQL query (identified by the variable name \"query\") and the SQL query execution (identified by the variable name \"result\") as input, and the final prompt as the output.\n",
        "* The chat model has the prompt as he input and the AIMessage with the response in natural language as the output.\n",
        "* The StrOutputParser has the AIMessage with the response in natural language as the input and the response in natural language as a string of text as the output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60fcad81-c02c-4f66-9a51-a5ceb15c6f5d",
      "metadata": {
        "id": "60fcad81-c02c-4f66-9a51-a5ceb15c6f5d"
      },
      "source": [
        "#### About the role of .assign() in this chain\n",
        "In this exercise we have learned more about the .assign() built-in method for Runnables. We have seen that the .assign() method **allows us to include additional keys and values** based on existing input.\n",
        "* With the first .assign(), the write_query chain has the question as input and the SQL query (identified by the variable name \"query\") as output.\n",
        "* With the second .assign(), the execute_query chain has the SQL query as input and the SQL query execution (identified by the variable name \"result\") as output.\n",
        "\n",
        "The .assign() method allows us to add new keys and values to the output of a Runnable **while keeping the original keys and values intact**. See the process again:\n",
        "* We use RunnablePassthrough to get that \"question\" variable, and we use .assign() twice to get the other two variables required by the prompt template: \"query\" and \"result\".\n",
        "* With the first .assign(), the write_query chain has que question as input and the SQL query (identified by the variable name \"query\") as output.\n",
        "* With the second .assign(), the execute_query chain has the SQL query as input and the SQL query execution (identified by the variable name \"result\") as output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa144596-cd5d-498c-97e0-4406f1e9f69f",
      "metadata": {
        "id": "fa144596-cd5d-498c-97e0-4406f1e9f69f"
      },
      "source": [
        "## How to execute the code from Visual Studio Code\n",
        "* In Visual Studio Code, see the file 004-invoke-stream-batch.py\n",
        "* In terminal, make sure you are in the directory of the file and run:\n",
        "    * python 001-qa-from-sql.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab30035",
      "metadata": {
        "id": "4ab30035"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}